{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer, Categorical\n",
    "import joblib\n",
    "import gc\n",
    "import itertools\n",
    "from skopt import gp_minimize\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "abo_path = 'D:/Users/masoodw/ML_FINANCE/asigmo/github/asigmo/data/Iris/iris.data'\n",
    "p_df_raw = pd.read_csv(abo_path, sep=',', encoding=\"UTF-8\", names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = p_df_raw.drop(\"class\", axis=1)\n",
    "df_y = LabelEncoder().fit_transform(list(p_df_raw[\"class\"]))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    0\n",
       "sepal_width     0\n",
       "petal_length    0\n",
       "petal_width     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "space  = [ Real(0.2, 10, name='eps')          \n",
    "          ,Integer(5, 50, name='min_samples')\n",
    "          ,Categorical(['euclidean', 'l1', 'l2'])\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(values):\n",
    "    \n",
    "    #print('\\nNext set of params.....',params)\n",
    "            \n",
    "        # Fit model on feature_set and calculate validation AUROC\n",
    "        \n",
    "    db = DBSCAN(eps=values[0], \n",
    "                min_samples=values[1],\n",
    "                metric=values[2],\n",
    "               ).fit(df_X)\n",
    "    \n",
    "    labels = db.labels_\n",
    "    \n",
    "    #sill = metrics.silhouette_score(df_X, labels, metric='euclidean', sample_size=None)  ### best score is 1\n",
    "    v_measure = metrics.homogeneity_completeness_v_measure(df_y, labels)[2]\n",
    "    \n",
    "    #sill = metrics.silhouette_score(df_X, db.labels_, metric='euclidean', sample_size=None)  ### best score is 1\n",
    "    \n",
    "    print('v_measure.....', v_measure)\n",
    "    #print('sill.....', sill)\n",
    "    \n",
    "    #gc.collect()\n",
    "    \n",
    "    #return  np.mean(train_auc_list)\n",
    "    return -v_measure\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_measure..... 0.0\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.6301893568173853\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.6889051517417055\n",
      "v_measure..... 0.5046811542838697\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.7130987813117572\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.7098236529971127\n",
      "v_measure..... 0.192571172828806\n",
      "v_measure..... 0.7098236529971127\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.0\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.7336804366512104\n",
      "v_measure..... 0.7336804366512104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Best score=-0.7337'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_gp = gp_minimize(objective, space, n_calls=50, random_state=0, n_random_starts=10, acq_func='LCB')\n",
    "\"Best score=%.4f\" % res_gp.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.878699264684464, 7, 'l1']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_gp.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=res_gp.x[0], min_samples=res_gp.x[1], metric=res_gp.x[2] ).fit(df_X)\n",
    "labels = db.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 2\n",
      "Estimated number of noise points: 0\n"
     ]
    }
   ],
   "source": [
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "0.6666666666666666\n",
      "Confusion Matrix\n",
      "[[50  0  0]\n",
      " [ 0 50  0]\n",
      " [ 0 50  0]]\n",
      "Confusion Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.50      1.00      0.67        50\n",
      "           2       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.67       150\n",
      "   macro avg       0.50      0.67      0.56       150\n",
      "weighted avg       0.50      0.67      0.56       150\n",
      "\n",
      "f1 score\n",
      "0.5555555555555555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\algo_trading\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy')\n",
    "print(metrics.accuracy_score(df_y, labels))\n",
    "print('Confusion Matrix')\n",
    "print(metrics.confusion_matrix(df_y, labels))\n",
    "print('Confusion Report')\n",
    "print(metrics.classification_report(df_y, labels))\n",
    "print('f1 score')\n",
    "print(metrics.f1_score(df_y, labels, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
